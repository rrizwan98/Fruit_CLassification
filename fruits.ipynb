{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fruits.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMd1jnhJ6ec5u4Kudjk+inq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rrizwan98/Fruit_CLassification/blob/main/fruits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWOakyUbIxyK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "8dad9e68-b344-4f0e-a99d-7d46bcab08d0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxvyTXCuJBH4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "54963f5b-ddf4-48f6-a555-d60cefc1d3d7"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name='/content/drive/My Drive/5857_1166105_bundle_archive (1).zip'\n",
        "with ZipFile(file_name,'r')as zip:\n",
        "  zip.extractall()\n",
        "  print('raza')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "raza\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnQ9q5xPJb_Q"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "layers = keras.layers\n",
        "models = keras.models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWC6gb_4RGlj"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(64,3,3,activation='relu',input_shape=(64,64,3)))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "\n",
        "model.add(Conv2D(32,3,3,activation='relu'))\n",
        "model.add(MaxPooling2D(2,2))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(layers.Dense(360,activation='relu'))\n",
        "model.add(layers.Dense(256,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(layers.Dense(131,activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYzLf5DRXdmj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "30cb5262-4d69-4b62-e578-1e6926298cc1"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                  shear_range=0.2,\n",
        "                                  zoom_range=0.2,\n",
        "                                  horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_set = train_datagen.flow_from_directory('/content/fruits-360/Training',\n",
        "                                              target_size=(64, 64),\n",
        "                                              batch_size=32,\n",
        "                                              class_mode='categorical')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('/content/fruits-360/Test',\n",
        "                                            target_size=(64, 64),\n",
        "                                            batch_size=32,\n",
        "                                            class_mode='categorical')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 67692 images belonging to 131 classes.\n",
            "Found 22688 images belonging to 131 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYGCaV3ZJ7R9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "07fef753-1bae-489b-c231-a0bd926418a5"
      },
      "source": [
        "history=model.fit_generator(train_set,\n",
        "                            steps_per_epoch=1000,\n",
        "                            epochs=10,\n",
        "                            validation_data=test_set,\n",
        "                            validation_steps=2000)       "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 1.0958 - accuracy: 0.6365WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 1.0958 - accuracy: 0.6365 - val_loss: 0.8503 - val_accuracy: 0.7418\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.9471 - accuracy: 0.6824WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.9471 - accuracy: 0.6824 - val_loss: 0.7803 - val_accuracy: 0.7510\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.8234 - accuracy: 0.7228WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
            "1000/1000 [==============================] - 75s 75ms/step - loss: 0.8234 - accuracy: 0.7228 - val_loss: 0.6801 - val_accuracy: 0.7823\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.7412 - accuracy: 0.7502WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.7412 - accuracy: 0.7502 - val_loss: 0.6156 - val_accuracy: 0.8029\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.6858 - accuracy: 0.7660WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.6858 - accuracy: 0.7660 - val_loss: 0.5633 - val_accuracy: 0.8211\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.6345 - accuracy: 0.7854WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
            "1000/1000 [==============================] - 75s 75ms/step - loss: 0.6345 - accuracy: 0.7854 - val_loss: 0.5620 - val_accuracy: 0.8342\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.5694 - accuracy: 0.8058WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
            "1000/1000 [==============================] - 75s 75ms/step - loss: 0.5694 - accuracy: 0.8058 - val_loss: 0.5624 - val_accuracy: 0.8306\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.5350 - accuracy: 0.8154WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
            "1000/1000 [==============================] - 75s 75ms/step - loss: 0.5350 - accuracy: 0.8154 - val_loss: 0.7524 - val_accuracy: 0.7810\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.5130 - accuracy: 0.8248WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.5130 - accuracy: 0.8248 - val_loss: 0.5470 - val_accuracy: 0.8338\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.4722 - accuracy: 0.8384WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 2000 batches). You may need to use the repeat() function when building your dataset.\n",
            "1000/1000 [==============================] - 75s 75ms/step - loss: 0.4722 - accuracy: 0.8384 - val_loss: 0.6696 - val_accuracy: 0.7979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajsq5kyUtcfX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "01479272-2f6a-4530-8812-f3a515edff8d"
      },
      "source": [
        "model.evaluate(test_set,\\\n",
        "               batch_size=32,verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "709/709 - 13s - loss: 0.6696 - accuracy: 0.7979\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6695543527603149, 0.7979108095169067]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_w_95dnKtws",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c67ae687-d98f-42f2-cf77-12f0a8ba3250"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "test_image=image.load_img('/content/fruits-360/test-multiple_fruits/Bananas(lady_finger)1.jpg',target_size=(64,64))\n",
        "test_image=image.img_to_array(test_image)\n",
        "test_image=np.expand_dims(test_image,axis=0)\n",
        "result=model.predict(test_image)\n",
        "train_set.class_indices\n",
        "if result[0][0]==6:\n",
        "  prediction='apple'\n",
        "  print(prediction)\n",
        "else:\n",
        "  prediction='field'\n",
        "  print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "field\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SkkUehgrdCK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}